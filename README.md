# Soft Actor Critic
#### Project by Hanqing Li, Kumar Utkarsh, Richard Suhendra
#### For the purposes of EE 473: Deep Reinforcement Learning Final Project

### YouTube video
https://www.youtube.com/watch?v=lEPWVFjySCg

### Important files

**Part1_Env_AC.ipynb** Explanation of gym environments used and our Actor Critic main file. Used mostly for comparison to SAC. Can be skipped over if not interested. Requires *train.py*, *buffer.py*, *utils.py*, and *model.py* to run.

**Part2_SAC.ipynb** Implementation of Soft Actor Critic by Tuomas Haarnoja. Comparison of all three methods used (AC, SAC, SAC with automatic temperature tuning) on gym environments. 

1. Haarnoja, T., Zhou, A., Abbeel, P., and Levine, S. Soft actor-critic: Off-policy maximum entropy deep reinforcement learning with a stochastic actor. In International Conference on Machine Learning (ICML), 2018c.

2. T. Haarnoja, A. Zhou, K. Hartikainen, G. Tucker, S. Ha, J. Tan, V. Kumar, H. Zhu, A. Gupta, P. Abbeel, and S. Levine. Soft actor-critic algorithms and applications. CoRR, abs/1812.05905, 2018.

# Disclaimer
All Jupyter notebooks run best on Google Colab. We do not guarantee they run as smoothly elsewhere. 
